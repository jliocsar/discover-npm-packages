{ argv, exit, stdout } from node:process
{ type Response, fetch } from undici
pino from pino
pretty from pino-pretty
minimist from minimist
removeMd from remove-markdown
* as colorette from colorette
{ Octokit } from octokit
type { TPackageParent, TPackage, TPackageDownloads } from ./types.civet
{ url, curry, ascByDownloads, writeYaml } from ./utils.civet

NPM_REGISTRY_URL := 'https://registry.npmjs.org'
NPM_DOWNLOADS_API_URL := 'https://api.npmjs.org/downloads/point/last-month'
NPM_PACKAGE_URL := 'https://www.npmjs.com/package'
HARD_CRAWL_LIMIT := 5
DEFAULT_CRAWL_LIMIT := 2
DEFAULT_README_PREVIEW_LIMIT := 500

octokit := new Octokit auth: process.env.GITHUB_PERSONAL_ACCESS_TOKEN!
logger := pino pretty { +colorize, +singleLine }

printHelp := ->
  stdout.write `
Usage: bun start ${colorette.dim '[options]'} <...packages>

Options:
  -c, --crawl ${colorette.blue '<number>'}  Crawl limit ${colorette.dim '(default: 2)'}
  -l, --limit ${colorette.blue '<number>'}  Readme preview limit ${colorette.dim '(default: 500)'}
  -h, --help            Show this help message and exit

`

{ _: packages, crawl, limit } := minimist argv.slice(2),
  alias:
    c: 'crawl'
    l: 'limit'
  default: 
    crawl: DEFAULT_CRAWL_LIMIT
    limit: DEFAULT_README_PREVIEW_LIMIT

if packages.length is 0
  logger.warn 'No packages specified!'
  printHelp()
  exit 1

if crawl > HARD_CRAWL_LIMIT
  logger.warn 'Crawl limit is too high! Max. is %d', HARD_CRAWL_LIMIT
  printHelp()
  exit 1

operator fromBufferOf := Buffer.from

toJSON := <T> -> (res: Response) -> res.json() as T

getNpmPackage := (pkg: string) ->
  url NPM_REGISTRY_URL, `${pkg}/latest` |> fetch |> await |> toJSON<TPackage>()

getNpmPackagesDownloads := (pkg: string) ->
  url NPM_DOWNLOADS_API_URL, pkg |> fetch |> await |> toJSON<TPackageDownloads>()

getReadme := (owner: string, repo: string) ->
  octokit.rest.repos.getReadme { owner, repo }
    |> await
    |> .data.content
    |> & fromBufferOf 'base64'
    |> .toString()

getReadmePreview := (repositoryUrl: string) ->
  [owner, repo] := repositoryUrl
    |> .replace /(^git:\/\/github\.com\/|\.git$)/, ''
    |> .split '/'
  getReadme owner, repo
    |> await
    |> removeMd
    |> .replace /\n+/g, '\n'
    |> .slice 0, limit
    |> & + '...'

isGithub := (npmPkg: TPackage) ->
  npmPkg.repository? and /^git:\/\/github\.com/.test npmPkg.repository.url

crawlNpmPackages := curry (crawls = 0, pkgs: string[]) ->
  await.all
    for pkg of pkgs
      npmPkg := pkg |> getNpmPackage |> await
      npmPkgLastMonthDownloads := pkg |> getNpmPackagesDownloads |> await
      parent := {
        name: pkg
        url NPM_PACKAGE_URL, pkg
        npmPkg{description}
        npmPkgLastMonthDownloads{downloads}
        readmePreview: if isGithub npmPkg then
          npmPkg.repository.url |> getReadmePreview |> await
        children: unless crawls is crawl
          Object.assign {}, npmPkg.dependencies, npmPkg.devDependencies, npmPkg.peerDependencies
            |> Object.keys
            |> crawlNpmPackages crawls + 1
            |> await
            |> .sort ascByDownloads
      } satisfies TPackageParent
      logger.info parent
      parent

main := ->
  packages
    |> crawlNpmPackages()
    |> await
    |> writeYaml 'output.yaml'

logger.info 'Running for %d packages, using crawl limit of %d', packages.length, crawl

await main()
